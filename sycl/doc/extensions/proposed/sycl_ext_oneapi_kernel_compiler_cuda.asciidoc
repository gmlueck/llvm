= sycl_ext_oneapi_kernel_compiler_opencl

:source-highlighter: coderay
:coderay-linenums-mode: table

// This section needs to be after the document title.
:doctype: book
:toc2:
:toc: left
:encoding: utf-8
:lang: en
:dpcpp: pass:[DPC++]
:endnote: &#8212;{nbsp}end{nbsp}note

// Set the default source code type in this document to C++,
// for syntax highlighting purposes.  This is needed because
// docbook uses c++ and html5 uses cpp.
:language: {basebackend@docbook:c++:cpp}


== Notice

[%hardbreaks]
Copyright (C) 2024-2024 Intel Corporation.  All rights reserved.

Khronos(R) is a registered trademark and SYCL(TM) and SPIR(TM) are trademarks
of The Khronos Group Inc.
OpenCL(TM) is a trademark of Apple Inc. used by permission by Khronos.


== Contact

To report problems with this extension, please open a new issue at:

https://github.com/intel/llvm/issues


== Dependencies

This extension is written against the SYCL 2020 revision 8 specification.
All references below to the "core SYCL specification" or to section numbers in
the SYCL specification refer to that revision.

This extension also depends on the following other SYCL extensions:

* link:../experimental/sycl_ext_oneapi_kernel_compiler.asciidoc[
  sycl_ext_oneapi_kernel_compiler]
* link:../proposed/sycl_ext_oneapi_work_group_specific.asciidoc[
  sycl_ext_oneapi_work_group_specific]


== Status

This is a proposed extension specification, intended to gather community
feedback.  Interfaces defined in this specification may not be implemented yet
or may be in a preliminary state.  The specification itself may also change in
incompatible ways before it is finalized.  *Shipping software products should
not rely on APIs defined in this specification.*


== Overview

This is an extension to
link:../experimental/sycl_ext_oneapi_kernel_compiler.asciidoc[
sycl_ext_oneapi_kernel_compiler], which allows an application to define a
kernel in the CUDA language when dynamically compiling a kernel from
source.


== Specification

=== Feature test macro

This extension provides a feature-test macro as described in the core SYCL
specification.
An implementation supporting this extension must predefine the macro
`SYCL_EXT_ONEAPI_KERNEL_COMPILER_CUDA`
to one of the values defined in the table below.
Applications can test for the existence of this macro to determine if the
implementation supports this feature, or applications can test the macro's
value to determine which of the extension's features the implementation
supports.

[%header,cols="1,5"]
|===
|Value
|Description

|1
|The APIs of this experimental extension are not versioned, so the
 feature-test macro always has this value.
|===

=== New source language enumerator

This extension adds the `opencl` enumerator to the `source_language`
enumeration, which indicates that a kernel bundle defines kernels in the
CUDA language.

```
namespace sycl::ext::oneapi::experimental {

enum class source_language : /*unspecified*/ {
  // ...
  cuda
};

} // namespace sycl::ext::oneapi::experimental
```

=== Source code is text format

Kernels written in the `cuda` language are text format.
As a result, the application must use the overload of
`create_kernel_bundle_from_source` taking `std::string` when creating a kernel
bundle from this language.

=== Build options

The `build_options` property accepts any of the compiler options defined in
link:https://docs.nvidia.com/cuda/nvrtc/index.html#supported-compile-options[
section 3.4] of the CUDA NVRTC documentation.

Each option must be passed as a separate string.
If an option has an argument, then the option and the argument must be passed
in the same string (e.g. `"-D=<def>"` or `"-D <def>"`).

=== Obtaining a kernel

When the kernel is defined in the language `source_language::cuda`, the host
code may query for the kernel or obtain the `kernel` object using either the
kernel's name as it is generated by the compiler (i.e. the C++ mangled name) or
by using the `registered_kernel_names` property.

==== Using the compiler-generated name

If the kernel is declared as `extern "C"`, the compiler generates the kernel
name exactly as it appears in the source code (i.e. there is no name mangling).
Therefore, it is easy to query for the kernel by using the compiler-generated
name.
For example, if the kernel is defined like this in the source code string:

```
std::string source = R"""(
  extern "C" __global__
  void foo(int *in, int *out) {/*...*/}
)""";
```

Then the application's host code can query for the kernel like this:

```
sycl::kernel_bundle<sycl::bundle_state::executable> kb = /*...*/;
sycl::kernel k = kb.ext_oneapi_get_kernel("foo");
```

==== Using the `registered_kernel_names` property

When the kernel is not declared as `extern "C"`, the compiler generates a
mangled name, so it is more convenient to use the `registered_kernel_names`
property.
Each string in the property must be the C++ expression for a pointer to a
kernel function.
These expression strings are conceptually compiled at the bottom of source
code.
To illustrate, consider source code that defines a kernel like this:

```
std::string source = R"""(
  namespace mykernels {

  __global__
  void bar(int *in, int *out) {/*...*/}

  } // namespace mykernels
)""";
```

The host code can compile this and get the kernel's `kernel` object like so:

```
sycl::kernel_bundle<sycl::bundle_state::ext_oneapi_source> kb_src = /*...*/;

sycl::kernel_bundle<sycl::bundle_state::executable> kb = syclex::build(kb_src,
  syclex::properties{syclex::registered_kernel_names{"mykernels::bar"}});

sycl::kernel k = kb.ext_oneapi_get_kernel("mykernels::bar");
```

The C++ expression `"mykernels::bar"` computes the address of the kernel
function `bar`.
The host code then passes the same string (`"mykernels::bar"`) to
`ext_oneapi_get_kernel` in order to get the `kernel` object.
The string must have exactly the same content as the string that was used to
construct the property, without even any whitespace differences.

The application can also obtain the compiler-generated (i.e. mangled) name for
the kernel by calling `ext_oneapi_get_raw_kernel_name` like this:

```
sycl::kernel_bundle<sycl::bundle_state::ext_oneapi_source> kb_src = /*...*/;

sycl::kernel_bundle<sycl::bundle_state::executable> kb = syclex::build(kb_src,
  syclex::properties{syclex::registered_kernel_names{"mykernels::bar"}});

std::string mangled_name = kb.ext_oneapi_get_raw_kernel_name("mykernels::bar");
```

Again, the string passed to `ext_oneapi_get_raw_kernel_name` must have exactly
the same content as the string that was used to construct the
`registered_kernel_names` property.
The application may also pass this compiler-generated (i.e. mangled) name to
`ext_oneapi_get_kernel` in order to get the `kernel` object.

==== Instantiating templated kernel functions

The `registered_kernel_names` property can also be used to instantiate a
kernel that is defined as a function template.
For example, consider source code that defines a kernel function template like
this:

```
std::string source = R"""(
  template<typename T>
  __global__
  void bartmpl(T *in, T *out) {/*...*/}
)""";
```

The application can use the `registered_kernel_names` property to instantiate
the template for specific template arguments.
For example, this host code instantiates the template twice and gets a `kernel`
object for each instantiation:

```
sycl::kernel_bundle<sycl::bundle_state::ext_oneapi_source> kb_src = /*...*/;

sycl::kernel_bundle<sycl::bundle_state::executable> kb = syclex::build(kb_src,
  syclex::properties{syclex::registered_kernel_names{{"bartmpl<float>", "bartmpl<int>"}});

sycl::kernel k_float = kb.ext_oneapi_get_kernel("bartmpl<float>");
sycl::kernel k_int = kb.ext_oneapi_get_kernel("bartmpl<int>");
```


=== Passing kernel arguments

All types of CUDA arguments are supported by this extension.
Each argument's value is byte-wise copied, so each argument value on the SYCL
side must have a device copyable type.
It is the application's responsibility to pass a SYCL argument whose size and
representation matches the corresponding CUDA argument.

There is a special case for CUDA arguments of pointer type.
For this argument type, the application may pass either a SYCL USM pointer or
an `accessor` whose target is `target::device`.

[_Note:_ CUDA has no argument type that matches `local_accessor`, so
applications may not pass `local_accessor` as a kernel argument.
However, see the section "Dynamic shared memory" below.
_{endnote}_]

=== Dynamic shared memory

If the CUDA kernel declares an unsized `+__shared__+` array, the size of the
array is not determined when the kernel is compiled.
Instead, the size is determined when the kernel is launched, referred to as
"dynamic shared memory" in the CUDA documentation.
This extension also supports CUDA kernels with dynamic shared memory.
To set the size of this memory, launch the kernel using the
`work_group_specific_size` property, which is defined in the 
link:../proposed/sycl_ext_oneapi_work_group_specific.asciidoc[
sycl_ext_oneapi_work_group_specific] extension.

=== Iteration space and the CUDA grid size

A `kernel` object created from CUDA source code must be launched either as a
single-task kernel or as an nd-range kernel.
Attempting to launch such a kernel with a simple range iteration space results
in undefined behavior.

If the kernel is launched as a single-task kernel, the CUDA grid has one thread
block of one thread.

If the kernel is launched as an nd-range kernel, the CUDA grid has the same
number of dimensions as the SYCL nd-range.
The number of CUDA threads in each dimension of the CUDA thread block is the
same as the corresponding dimension in the SYCL local range.
The number of CUDA thread blocks in each dimension is computed by dividing the
corresponding dimension of the SYCL global range by the SYCL local range.
For example, launching the kernel with `nd_range{{1024}, {16}}` results in 64
CUDA thread blocks (64 = 1024 / 16), where each thread block has 16 CUDA
threads.

Dimension 0 in the SYCL `nd_range` corresponds to the "x" dimension in the CUDA
grid, dimension 1 in the SYCL `nd_range` corresponds to the "y" dimension in
the CUDA grid, and dimension 2 in the SYCL `nd_range` corresponds to the "z"
dimension in the CUDA grid.
If the `nd_range` has only 2 dimensions, the "z" dimension in the CUDA grid
has 1 element.
If the `nd_range` has only 1 dimension, the "y" and "z" dimensions in the
CUDA grid each have 1 element.

To illustrate, launching a kernel with `nd_range{{2048, 512}, {16, 8}}` results
in a CUDA thread block of size `(128, 64, 1)` (i.e. 128 thread-block elements
in the "x" dimension and 64 thread-block elements in the "y" dimension, and 1
thread-block element in the "z" dimension).
Each CUDA thread block has `(16, 8, 1)` threads (i.e. 16 threads in the "x"
dimension, 8 threads in the "y" dimension, and 1 thread in the "z" dimension).


== Examples

=== Simple example

The following example shows a simple SYCL program that defines a CUDA
kernel as a string and then compiles and launches it.

```
#include <sycl/sycl.hpp>
namespace syclex = sycl::ext::oneapi::experimental;

int main() {
  sycl::queue q;

  // Kernel defined as string with CUDA source code.  This could be dynamically
  // generated instead of a literal.
  std::string source = R"""(
    extern "C" __global__
    void my_kernel(int *in, int *out) {
      size_t i = blockIdx.x * blockDim.x + threadIdx.x;
      out[i] = in[i]*2 + 100;
    }
  )""";

  sycl::kernel_bundle<sycl::bundle_state::ext_oneapi_source> kb_src =
    syclex::create_kernel_bundle_from_source(
      q.get_context(),
      syclex::source_language::cuda,
      source);

  // Compile and link the kernel from the source definition.
  sycl::kernel_bundle<sycl::bundle_state::executable> kb_exe =
    syclex::build(kb_src);

  // Get a "kernel" object representing the kernel defined in the
  // source string.
  sycl::kernel k = kb_exe.ext_oneapi_get_kernel("my_kernel");

  constexpr int N = 4;
  cl_int input[N] = {0, 1, 2, 3};
  cl_int output[N] = {};

  sycl::buffer inputbuf(input, sycl::range{N});
  sycl::buffer outputbuf(output, sycl::range{N});

  q.submit([&](sycl::handler &cgh) {
    sycl::accessor in{inputbuf, cgh, sycl::read_only};
    sycl::accessor out{outputbuf, cgh, sycl::read_write};

    // Each argument to the kernel is a SYCL accessor.
    cgh.set_args(in, out);

    // Invoke the kernel over an nd-range.
    cgh.parallel_for(sycl::nd_range{{N}, {N}}, k);
  });
}
```


== Issues

